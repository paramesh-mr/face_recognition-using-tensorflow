{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from align_custom import AlignCustom\n",
    "from face_feature import FaceFeature\n",
    "from mtcnn_detect import MTCNNDetect\n",
    "from tf_graph import FaceRecGraph\n",
    "import argparse\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    mode = args.mode\n",
    "    if(mode == \"camera\"):\n",
    "        camera_recog()\n",
    "    elif mode == \"input\":\n",
    "        create_manual_data();\n",
    "    else:\n",
    "        raise ValueError(\"Unimplemented mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_recog():\n",
    "    print(\"[INFO] camera sensor warming up...\")\n",
    "    vs = cv2.VideoCapture(0); #get input from webcam\n",
    "    detect_time = time.time()\n",
    "    while True:\n",
    "        _,frame = vs.read();\n",
    "        #u can certainly add a roi here but for the sake of a demo i'll just leave it as simple as this\n",
    "        rects, landmarks = face_detect.detect_face(frame,80);#min face size is set to 80x80\n",
    "        aligns = []\n",
    "        positions = []\n",
    "\n",
    "        for (i, rect) in enumerate(rects):\n",
    "            aligned_face, face_pos = aligner.align(160,frame,landmarks[:,i])\n",
    "            if len(aligned_face) == 160 and len(aligned_face[0]) == 160:\n",
    "                aligns.append(aligned_face)\n",
    "                positions.append(face_pos)\n",
    "            else: \n",
    "                print(\"Align face failed\") #log        \n",
    "        if(len(aligns) > 0):\n",
    "            features_arr = extract_feature.get_features(aligns)\n",
    "            recog_data = findPeople(features_arr,positions)\n",
    "            for (i,rect) in enumerate(rects):\n",
    "                cv2.rectangle(frame,(rect[0],rect[1]),(rect[2],rect[3]),(255,0,0)) #draw bounding box for the face\n",
    "                cv2.putText(frame,recog_data[i][0]+\" - \"+str(recog_data[i][1])+\"%\",(rect[0],rect[1]),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1,cv2.LINE_AA)\n",
    "        cv2.imshow(\"Frame\",frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord(\"q\"):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findPeople(features_arr, positions, thres = 0.6, percent_thres = 70):\n",
    "    f = open('./facerec_128D.txt','r')\n",
    "    data_set = json.loads(f.read());\n",
    "    returnRes = [];\n",
    "    for (i,features_128D) in enumerate(features_arr):\n",
    "        result = \"Unknown\";\n",
    "        smallest = sys.maxsize\n",
    "        for person in data_set.keys():\n",
    "            person_data = data_set[person][positions[i]];\n",
    "            for data in person_data:\n",
    "                distance = np.sqrt(np.sum(np.square(data-features_128D)))\n",
    "                if(distance < smallest):\n",
    "                    smallest = distance;\n",
    "                    result = person;\n",
    "        percentage =  min(100, 100 * thres / smallest)\n",
    "        if percentage <= percent_thres :\n",
    "            result = \"Unknown\"\n",
    "        returnRes.append((result,percentage))\n",
    "    return returnRes    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_manual_data():\n",
    "    vs = cv2.VideoCapture(0); #get input from webcam\n",
    "    print(\"Please input new user ID:\")\n",
    "    new_name = input(); #ez python input()\n",
    "    f = open('./facerec_128D.txt','r');\n",
    "    data_set = json.loads(f.read());\n",
    "    person_imgs = {\"Left\" : [], \"Right\": [], \"Center\": []};\n",
    "    person_features = {\"Left\" : [], \"Right\": [], \"Center\": []};\n",
    "    print(\"Please start turning slowly. Press 'q' to save and add this new user to the dataset\");\n",
    "    while True:\n",
    "        _, frame = vs.read();\n",
    "        rects, landmarks = face_detect.detect_face(frame, 80);  # min face size is set to 80x80\n",
    "        for (i, rect) in enumerate(rects):\n",
    "            aligned_frame, pos = aligner.align(160,frame,landmarks[:,i]);\n",
    "            if len(aligned_frame) == 160 and len(aligned_frame[0]) == 160:\n",
    "                person_imgs[pos].append(aligned_frame)\n",
    "                cv2.imshow(\"Captured face\", aligned_frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "    for pos in person_imgs: #there r some exceptions here, but I'll just leave it as this to keep it simple\n",
    "        person_features[pos] = [np.mean(extract_feature.get_features(person_imgs[pos]),axis=0).tolist()]\n",
    "    data_set[new_name] = person_features;\n",
    "    f = open('./facerec_128D.txt', 'w');\n",
    "    f.write(json.dumps(data_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--mode MODE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\PARAMESH\\AppData\\Roaming\\jupyter\\runtime\\kernel-8e73587d-e4d4-4ad1-af51-0d4dede6e87c.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--mode\", type=str, help=\"Run camera recognition\", default=\"camera\")\n",
    "    args = parser.parse_args(sys.argv[1:]);\n",
    "    FRGraph = FaceRecGraph();\n",
    "    MTCNNGraph = FaceRecGraph();\n",
    "    aligner = AlignCustom();\n",
    "    extract_feature = FaceFeature(FRGraph)\n",
    "    face_detect = MTCNNDetect(MTCNNGraph, scale_factor=2); #scale_factor, rescales image for faster detection\n",
    "    main(args);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
